{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bfb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3966 sha256=061298316065b6687ca915321781e26eff2e2d62503a7f683c9dc501c05509e3\n",
      "  Stored in directory: c:\\users\\tejaswini\\appdata\\local\\pip\\cache\\wheels\\55\\f0\\2c\\81637d42670985178b77df6d41b9b6c6dc18c94818447414b9\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09fde41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import docx2txt\n",
    "job_des = docx2txt.process('Resume_scanner/Jobdes_unilever.docx')\n",
    "resume= docx2txt.process('Resume_scanner/KrishnaSaiTejaswini_Kambhampati_SCU_MSIS_DE_Role.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d320687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tejaswini (TJ) Kambhampati\n",
      "\n",
      "Cupertino, CA 95014\n",
      "\n",
      "kkambhampati@scu.edu, +1 (669)-293-9092, www.linkedin.com/in/tejaswini-kambhampati-b9140b149 , https://github.com/Tejaswini-popuri?tab=repositories \n",
      "\n",
      "\n",
      "\n",
      "EDUCATION \n",
      "\n",
      "Santa Clara University, Leavey School of Business\t\t\t\t\t\t \t\t    Santa Clara, CA\n",
      "\n",
      "Master of Information Systems, Cumulative GPA: 3.7   \t\t\t                   \t\t   Graduation in June 2023                                                         \n",
      "\n",
      "Relevant Course Work: Big Data Modelling and Analytics, Database Management Systems Design and SQL, Data Analytics with Python, Information Systems Analysis and Design, Object Oriented Design and Programming using Java\n",
      "\n",
      "\n",
      "\n",
      "Jawaharlal Nehru Technological University \t\t\t\t\t                                 \t        Andhra Pradesh, India\n",
      "\n",
      "Bachelors in Aeronautical Engineering\t                     \t\t\t\t\t\t     Graduated in May 2013\n",
      "\n",
      "Published and presented an article on “Computational Airflow on Hypersonic Air Engines” at the convention of The Institute of Engineers, India.\n",
      "\n",
      "TECHNICAL SKILLS\n",
      "\n",
      "Programming Languages:  Python, SQL, Java, C, Bash\n",
      "\n",
      "Tools: Snowflake, Teradata, SQL server, MySQL, Oracle DB, Tableau, Informatica PowerCenter, Jupyter Notebook, Amazon Athena\n",
      "\n",
      "Analytics and Data Science:  Data Mining & Analytics, Excel for Analytics, Machine learning, Supervised and Unsupervised learning, Time Series, Sentiment Analysis, Click Stream Analytics, Business Intelligence\n",
      "\n",
      "Technologies: ETL, Distributed File Systems, Apache Spark, NoSQL databases, MapReduce algorithms, Pandas, NumPy, Seaborn, Scikitlearn\n",
      "\n",
      "EXPERIENCE\n",
      "\n",
      "INFOSYS LTD \t\t\t\t\t\t\t\t\t\t              Bengaluru, Karnataka, India\n",
      "\n",
      "Senior Systems Engineer (Business Intelligence)\t\t\t\t\t\t       November 2014-February 2017\n",
      "\n",
      "CVS Medicare: \n",
      "\n",
      "Designed and developed complex mappings to move data from various source systems ranging from DB2, Flat Files to a common target area such as Data Marts using Informatica (9.x) applications.\n",
      "\n",
      "Pfizer R&D: \n",
      "\n",
      "Provided tier 2 and 3 production support to Autosys batch processes and performed trouble shooting using Informatica power center logs, LINUX/UNIX scripts and DB processes, detecting data inaccuracies and ensuring corrections in system of records. I partnered with 3 cross functional teams to efficiently deploy software releases in both User Acceptance Testing and Production environments.\n",
      "\n",
      "Received ‘INSTA AWARD’ from Infosys for extended support in successful deployment of projects into production.\n",
      "\n",
      "PAYACTIV LTD\t\t\t\t\t\t\t\t\t\t \t   San Jose, California, USA\n",
      "\n",
      "Project Reveal: Focused on end-to-end Customer journey and product analytics. Analyzed user activity including app navigation, feature usage & service adoption. Unlocking insights on user behavior to enhance Product Experience to cater to end customers.\n",
      "\n",
      "\n",
      "\n",
      "ACADEMIC PROJECTS\n",
      "\n",
      "Amazon Return Management System: code\n",
      "\n",
      "Designed and developed a database to manage order returns for an eCommerce Platform, following design principles, from constructing swim lane diagrams and ER diagrams to formulating views, triggers, stored procedures etc.\n",
      "\n",
      "YouTube Trending Videos Analysis (2020-21): code\n",
      "\n",
      "Led a team of 4 in performing extensive cleaning and analysis of dataset with creative visualizations (highlighting the findings through Time series plots spotting trends and demonstrating insights using Word Clouds). Trained an ML model using Decision tree regressor and predicted trending days of a video using linear regression model and another ML model (using Bag of words) to find the missing category of a video using Classification. \n",
      "\n",
      "Bookworms Vending Library: code\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "Designed a 24/7 Library kiosk, by applying System design principles, which offers full circulation functionality of a library and reduces the budget by 10% (Latest CA library renovation & modernization budget: $438 million).\n",
      "\n",
      "\n",
      "\n",
      "ADDITIONAL INFORMATION\n",
      "\n",
      "Interests:  Singing (Indian Classical Music), Audiobooks and Podcasts, Running\n",
      "\n",
      "Volunteer Experience: Social Media Marketing coordinator at ASHA for education (NGO), focused on rural education in India.\n"
     ]
    }
   ],
   "source": [
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b99236db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Data Scientist, you will be an integral part of the Information and Analytics team supporting the organization to enhance and drive overall top-line sales growth and profitability. This role will also interface with multiple key stakeholders and functional teams.\n",
      "\n",
      "In this role, you will be responsible for providing insights to the cross-functional business teams leveraging a variety of internal and external data sets, and advance analytic techniques to create value. This role will also interface with multiple stakeholders and teams on a consistent basis to deliver analytic outputs.  \n",
      "\n",
      "The ability to gain stakeholder consensus, build coalitions, and present a vision to the broader organization will be crucial for success. \n",
      "\n",
      "The ability to formulate hypothesis and draw inferences from different cross functional datasets and generate a story of insights is key. \n",
      "\n",
      "you have ability to transform data into insights which provide very clear direction to stakeholders on what actions are needed to drive transformation in the business.  \n",
      "\n",
      "Extensive experience solving analytical problems using quantitative approaches, a strong passion for empirical research and for answering hard questions with data. Analyze data, run descriptive statistics, generate prior distributions, explore relationships: correlation, covariance, causality, regression modeling, and build Bayesian Influence diagrams. Must be hands-on and must have worked on implementing data mining algorithms, work with cross-functional team members to identify and prioritize actionable, high-impact insights across a variety of core business areas. Strong experience in Data Visualization, Presentation and Story Telling. Ability to work independently as well as in a team environment. Partner with business, Data Scientists, and Engineers to create POCs/Pilots, demonstrate thought leadership and generate marketing insights. \n",
      "\n",
      "What You’ll Need To Succeed\n",
      "\n",
      "Required: \n",
      "\n",
      "Master’s degree in a related field (e.g. Applied Science, Data Science, Computer Science, Mathematics, Statistics, or another analytical field) \n",
      "\n",
      "At least 1 year data science experience\n",
      "\n",
      "Expertise in Machine Learning (ML), Data Science, AI, and Data Mining is required.\n",
      "\n",
      "Expertise in Data Wrangling, Engineering, Exploratory data analysis using statistics and programing.\n",
      "\n",
      "Expertise in ML algorithms such as PCA, LASSO, RIDGE, SVM, Bayesian, Random Forest, Boosting, Clustering, ARMA, Time Series modeling, Generalized Linear Models, Regression Models, Neural Networks, RNN, CNN, and LSTM is required.\n",
      "\n",
      "Expertise in building models using Python, Spark, Scala, SQL, R\n",
      "\n",
      "Active listening skills and deep analytical ability are required\n",
      "\n",
      "A passion for excellence and exceeding customer expectations is required\n",
      "\n",
      "Preferred\n",
      "\n",
      "PhD in a related field (e.g. Applied Science, Data Science, Computer Science, Mathematics, Statistics, or another analytical field)\n",
      "\n",
      "Consumer goods experience \n",
      "\n",
      "Preferred experience in Classification, Forecasting, Anomaly detection, Outliers analysis, Optimization, Trends analysis, Bayesian inference, Time-Series methods (ARMA/ARIMA), Markovian processes.\n",
      "\n",
      "Preferred experience in Java, C++, SAS, SPSS, Azure, Big Data, AWS\n",
      "\n",
      "Preferred experience in Text Mining and Natural Language Programming (NLP).\n"
     ]
    }
   ],
   "source": [
    "print(job_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7629dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def remove_links(corpus):\n",
    "        return re.sub(r'http\\S+', '', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ddb9b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tejaswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tejaswini\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = list(tokenize(text))\n",
    "    #res = ' '.join([stemmer.stem(t.lower()) for t in tokens if t.lower() not in stop_words]) \n",
    "    res = ' '.join([lemmatizer.lemmatize(t.lower()) for t in tokens if t.lower() not in stop_words]) \n",
    "    if len(res) == 0:\n",
    "        return ' '\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d82ac558",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [job_des,resume]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b22523c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = remove_links(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2db435ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(preprocessor=clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23d21dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = cv.fit_transform(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c0eb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6491d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = cosine_similarity(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21845aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.32917158]\n",
      " [0.32917158 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(sim_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
